#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•¦ç…Œ100MWå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºä¼˜åŒ–ä¸»ç¨‹åº

è¯¥è„šæœ¬æ•´åˆäº†:
1. æ•°æ®é¢„å¤„ç†
2. H-MOWOA-ABCä¼˜åŒ–ç®—æ³•
3. ç»“æœåˆ†æå’Œå¯è§†åŒ–
4. æ•°æ®é›†ç”Ÿæˆ

ä½œè€…: poboll
æ—¥æœŸ: 2025
ç”¨é€”: Scientific Data æœŸåˆŠæŠ•ç¨¿æ•°æ®é›†ç”Ÿæˆ
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from optimization.zoo_algorithm import H_MOWOA_ABC, OptimizationResult

class DunhuangHeliostatOptimizer:
    """
    æ•¦ç…Œå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºä¼˜åŒ–å™¨
    æ•´åˆæ•°æ®å¤„ç†ã€ä¼˜åŒ–ç®—æ³•å’Œç»“æœåˆ†æ
    """
    
    def __init__(self, config_file: str = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_file)
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.results_dir = os.path.join(self.project_root, "results")
        self.data_dir = os.path.join(self.project_root, "data")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(f"{self.results_dir}/figures", exist_ok=True)
        os.makedirs(f"{self.results_dir}/layouts", exist_ok=True)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = H_MOWOA_ABC(
            population_size=self.config['optimization']['population_size'],
            max_generations=self.config['optimization']['max_generations'],
            field_bounds=tuple(self.config['plant']['field_bounds']),
            num_heliostats=self.config['plant']['num_heliostats'],
            tower_position=tuple(self.config['plant']['tower_position']),
            heliostat_size=self.config['plant']['heliostat_size']
        )
        
    def _load_config(self, config_file: str = None) -> dict:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        """
        if config_file and os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤é…ç½® - åŸºäºæ•¦ç…Œ100MWç”µç«™å‚æ•°
            return {
                "plant": {
                    "name": "é¦–èˆªæ•¦ç…Œ100MWç†”ç›å¡”å¼å…‰çƒ­ç”µç«™",
                    "location": {
                        "latitude": 40.063,
                        "longitude": 94.426,
                        "elevation": 1267
                    },
                    "tower_position": [0, 0],
                    "tower_height": 263,
                    "field_bounds": [-800, 800, -800, 800],
                    "num_heliostats": 1000,
                    "heliostat_size": 115.7,
                    "rated_power": 100,
                    "storage_hours": 11
                },
                "optimization": {
                    "population_size": 50,
                    "max_generations": 100,
                    "algorithm": "H-MOWOA-ABC"
                },
                "objectives": {
                    "annual_energy": {"type": "maximize", "weight": 1.0},
                    "lcoe": {"type": "minimize", "weight": 1.0},
                    "flux_uniformity": {"type": "maximize", "weight": 1.0}
                }
            }
    
    def load_meteorological_data(self) -> pd.DataFrame:
        """
        åŠ è½½TMYæ°”è±¡æ•°æ®
        """
        tmy_file = os.path.join(self.data_dir, "raw", "tmy.1.csv")
        
        if not os.path.exists(tmy_file):
            raise FileNotFoundError(f"TMYæ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {tmy_file}")
        
        print(f"åŠ è½½TMYæ°”è±¡æ•°æ®: {tmy_file}")
        
        try:
            # è¯»å–æ–‡ä»¶å¤´ä¿¡æ¯
            with open(tmy_file, 'r') as f:
                lines = f.readlines()
            
            # è§£æå¤´éƒ¨ä¿¡æ¯
            latitude = float(lines[0].split(':')[1].strip())
            longitude = float(lines[1].split(':')[1].strip())
            elevation = float(lines[2].split(':')[1].strip())
            
            print(f"ç”µç«™ä½ç½®: {latitude:.3f}Â°N, {longitude:.3f}Â°E, æµ·æ‹”{elevation:.0f}m")
            
            # æ‰¾åˆ°æ•°æ®å¼€å§‹è¡Œ (åŒ…å«time(UTC)çš„è¡Œ)
            data_start_line = 0
            for i, line in enumerate(lines):
                if 'time(UTC)' in line:
                    data_start_line = i
                    break
            
            # è¯»å–æ°”è±¡æ•°æ®
            tmy_data = pd.read_csv(tmy_file, skiprows=data_start_line)
            
            # é‡å‘½ååˆ—ä»¥ä¾¿ä½¿ç”¨
            column_mapping = {
                'time(UTC)': 'datetime',
                'T2m': 'temperature',  # 2mæ¸©åº¦ (Â°C)
                'RH': 'humidity',      # ç›¸å¯¹æ¹¿åº¦ (%)
                'G(h)': 'ghi',         # å…¨çƒæ°´å¹³è¾å°„ (W/mÂ²)
                'Gb(n)': 'dni',        # ç›´æ¥æ³•å‘è¾å°„ (W/mÂ²)
                'Gd(h)': 'dhi',        # æ•£å°„æ°´å¹³è¾å°„ (W/mÂ²)
                'WS10m': 'wind_speed', # 10mé£é€Ÿ (m/s)
                'WD10m': 'wind_direction', # 10mé£å‘ (Â°)
                'SP': 'pressure'       # è¡¨é¢å‹åŠ› (Pa)
            }
            
            # é‡å‘½åå­˜åœ¨çš„åˆ—
            for old_name, new_name in column_mapping.items():
                if old_name in tmy_data.columns:
                    tmy_data = tmy_data.rename(columns={old_name: new_name})
            
            # è½¬æ¢æ—¶é—´æ ¼å¼
            if 'datetime' in tmy_data.columns:
                tmy_data['datetime'] = pd.to_datetime(tmy_data['datetime'], format='%Y%m%d:%H%M')
            
            print(f"TMYæ•°æ®åŒ…å« {len(tmy_data)} å°æ—¶çš„è®°å½•")
            print(f"æ•°æ®åˆ—: {list(tmy_data.columns)}")
            
            # æ·»åŠ ä½ç½®ä¿¡æ¯åˆ°æ•°æ®æ¡†
            tmy_data.attrs['latitude'] = latitude
            tmy_data.attrs['longitude'] = longitude
            tmy_data.attrs['elevation'] = elevation
            
            return tmy_data
            
        except Exception as e:
            print(f"è­¦å‘Š: TMYæ•°æ®åŠ è½½å¤±è´¥ - {str(e)}")
            print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­è¿è¡Œ")
            
            # ç”Ÿæˆæ¨¡æ‹Ÿçš„TMYæ•°æ®ç”¨äºæµ‹è¯•
            dates = pd.date_range('2020-01-01', periods=8760, freq='H')
            
            # ç®€å•çš„DNIæ¨¡å‹ (åŸºäºå¤ªé˜³é«˜åº¦è§’)
            hour_of_year = np.arange(8760)
            day_of_year = hour_of_year // 24 + 1
            hour_of_day = hour_of_year % 24
            
            # æ¨¡æ‹ŸDNI (è€ƒè™‘æ—¥å˜åŒ–å’Œå­£èŠ‚å˜åŒ–)
            dni_base = 800 * np.maximum(0, np.sin(np.pi * (hour_of_day - 6) / 12))
            seasonal_factor = 0.8 + 0.4 * np.cos(2 * np.pi * (day_of_year - 172) / 365)
            dni = dni_base * seasonal_factor * (0.8 + 0.2 * np.random.random(8760))
            
            tmy_data = pd.DataFrame({
                'datetime': dates,
                'dni': dni,
                'ghi': dni * 1.2,
                'dhi': dni * 0.1,
                'temperature': 20 + 15 * np.sin(2 * np.pi * day_of_year / 365) + 10 * np.sin(np.pi * hour_of_day / 12),
                'humidity': 30 + 20 * np.random.random(8760),
                'wind_speed': 2 + 3 * np.random.random(8760),
                'wind_direction': 180 + 90 * np.random.random(8760),
                'pressure': 85000 + 1000 * np.random.random(8760)
            })
            
            tmy_data.attrs['latitude'] = 40.063
            tmy_data.attrs['longitude'] = 94.426
            tmy_data.attrs['elevation'] = 1267
            
            print(f"ç”Ÿæˆæ¨¡æ‹ŸTMYæ•°æ®: {len(tmy_data)} å°æ—¶")
            
            return tmy_data
    
    def load_baseline_layout(self) -> pd.DataFrame:
        """
        åŠ è½½åŸºå‡†å®šæ—¥é•œå¸ƒå±€
        """
        layout_file = f"{self.data_dir}/processed/heliostat_layout.csv"
        
        if os.path.exists(layout_file):
            print(f"åŠ è½½åŸºå‡†å¸ƒå±€: {layout_file}")
            return pd.read_csv(layout_file)
        else:
            print("æœªæ‰¾åˆ°åŸºå‡†å¸ƒå±€æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç®—æ³•ç”Ÿæˆçš„å¾„å‘äº¤é”™å¸ƒå±€")
            return None
    
    def run_optimization(self) -> dict:
        """
        æ‰§è¡Œä¼˜åŒ–ç®—æ³•
        """
        print("\n" + "="*60)
        print("å¼€å§‹å®šæ—¥é•œåœºå¸ƒå±€ä¼˜åŒ–")
        print("="*60)
        
        # åŠ è½½æ•°æ®
        tmy_data = self.load_meteorological_data()
        baseline_layout = self.load_baseline_layout()
        
        # æ‰§è¡Œä¼˜åŒ–
        start_time = datetime.now()
        results = self.optimizer.optimize()
        end_time = datetime.now()
        
        optimization_time = (end_time - start_time).total_seconds()
        
        print(f"\nä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶: {optimization_time:.1f} ç§’")
        
        # æ·»åŠ å…ƒæ•°æ®
        results['metadata'] = {
            'optimization_time_seconds': optimization_time,
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'config': self.config,
            'tmy_data_points': len(tmy_data),
            'baseline_layout_available': baseline_layout is not None
        }
        
        return results
    
    def analyze_results(self, results: dict) -> dict:
        """
        åˆ†æä¼˜åŒ–ç»“æœ
        """
        print("\nåˆ†æä¼˜åŒ–ç»“æœ...")
        
        pareto_front = results['pareto_front']
        
        if not pareto_front:
            print("è­¦å‘Š: æœªæ‰¾åˆ°å¸•ç´¯æ‰˜å‰æ²¿è§£")
            return {}
        
        # ç»Ÿè®¡åˆ†æ
        annual_energies = [sol.objectives[0] for sol in pareto_front]
        lcoes = [sol.objectives[1] for sol in pareto_front]
        flux_uniformities = [sol.objectives[2] for sol in pareto_front]
        
        analysis = {
            'pareto_front_size': len(pareto_front),
            'annual_energy': {
                'min': min(annual_energies),
                'max': max(annual_energies),
                'mean': np.mean(annual_energies),
                'std': np.std(annual_energies)
            },
            'lcoe': {
                'min': min(lcoes),
                'max': max(lcoes),
                'mean': np.mean(lcoes),
                'std': np.std(lcoes)
            },
            'flux_uniformity': {
                'min': min(flux_uniformities),
                'max': max(flux_uniformities),
                'mean': np.mean(flux_uniformities),
                'std': np.std(flux_uniformities)
            }
        }
        
        # æ‰¾åˆ°æœ€ä½³æŠ˜è¡·è§£ (ä½¿ç”¨åŠ æƒå’Œæ–¹æ³•)
        best_compromise_idx = 0
        best_score = float('-inf')
        
        for i, sol in enumerate(pareto_front):
            # å½’ä¸€åŒ–ç›®æ ‡å€¼
            norm_energy = (sol.objectives[0] - analysis['annual_energy']['min']) / \
                         (analysis['annual_energy']['max'] - analysis['annual_energy']['min'] + 1e-10)
            norm_lcoe = 1 - (sol.objectives[1] - analysis['lcoe']['min']) / \
                       (analysis['lcoe']['max'] - analysis['lcoe']['min'] + 1e-10)
            norm_uniformity = (sol.objectives[2] - analysis['flux_uniformity']['min']) / \
                             (analysis['flux_uniformity']['max'] - analysis['flux_uniformity']['min'] + 1e-10)
            
            # è®¡ç®—åŠ æƒåˆ†æ•°
            score = (norm_energy * self.config['objectives']['annual_energy']['weight'] +
                    norm_lcoe * self.config['objectives']['lcoe']['weight'] +
                    norm_uniformity * self.config['objectives']['flux_uniformity']['weight'])
            
            if score > best_score:
                best_score = score
                best_compromise_idx = i
        
        analysis['best_compromise_solution'] = {
            'index': best_compromise_idx,
            'annual_energy': pareto_front[best_compromise_idx].objectives[0],
            'lcoe': pareto_front[best_compromise_idx].objectives[1],
            'flux_uniformity': pareto_front[best_compromise_idx].objectives[2],
            'score': best_score
        }
        
        print(f"å¸•ç´¯æ‰˜å‰æ²¿åŒ…å« {analysis['pareto_front_size']} ä¸ªè§£")
        print(f"å¹´å‘ç”µé‡èŒƒå›´: {analysis['annual_energy']['min']:.1f} - {analysis['annual_energy']['max']:.1f} MWh")
        print(f"LCOEèŒƒå›´: {analysis['lcoe']['min']:.1f} - {analysis['lcoe']['max']:.1f} $/MWh")
        print(f"çƒ­é€šé‡å‡åŒ€æ€§èŒƒå›´: {analysis['flux_uniformity']['min']:.3f} - {analysis['flux_uniformity']['max']:.3f}")
        
        best_sol = analysis['best_compromise_solution']
        print(f"\næœ€ä½³æŠ˜è¡·è§£:")
        print(f"  å¹´å‘ç”µé‡: {best_sol['annual_energy']:.1f} MWh")
        print(f"  LCOE: {best_sol['lcoe']:.1f} $/MWh")
        print(f"  çƒ­é€šé‡å‡åŒ€æ€§: {best_sol['flux_uniformity']:.3f}")
        
        return analysis
    
    def generate_dataset(self, results: dict, analysis: dict):
        """
        ç”Ÿæˆç¬¦åˆFAIRåŸåˆ™çš„æ•°æ®é›†
        """
        print("\nç”Ÿæˆæ•°æ®é›†...")
        
        # ä¿å­˜ä¼˜åŒ–ç»“æœ
        self.optimizer.save_results(results, self.results_dir)
        
        # ç”Ÿæˆæ•°æ®é›†å…ƒæ•°æ®
        metadata = {
            'dataset_info': {
                'title': 'æ•¦ç…Œ100MWå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºå¤šç›®æ ‡ä¼˜åŒ–æ•°æ®é›†',
                'description': 'åŸºäºH-MOWOA-ABCç®—æ³•çš„å®šæ—¥é•œåœºå¸ƒå±€ä¼˜åŒ–ç»“æœ',
                'version': '1.0',
                'creation_date': datetime.now().isoformat(),
                'license': 'CC-BY 4.0'
            },
            'plant_parameters': self.config['plant'],
            'optimization_parameters': self.config['optimization'],
            'results_summary': analysis,
            'data_files': {
                'pareto_front': 'pareto_front.csv',
                'optimization_history': 'optimization_history.csv',
                'optimal_layouts': 'optimal_layouts/*.csv'
            }
        }
        
        # ä¿å­˜å…ƒæ•°æ®
        with open(f"{self.results_dir}/dataset_metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ•°æ®é›†æ‘˜è¦æŠ¥å‘Š
        self._generate_summary_report(results, analysis)
        
        print(f"æ•°æ®é›†å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°: {self.results_dir}")
    
    def _generate_summary_report(self, results: dict, analysis: dict):
        """
        ç”Ÿæˆæ•°æ®é›†æ‘˜è¦æŠ¥å‘Š
        """
        report_content = f"""
# æ•¦ç…Œ100MWå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºä¼˜åŒ–æ•°æ®é›†æ‘˜è¦æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- ç”µç«™åç§°: {self.config['plant']['name']}
- åœ°ç†ä½ç½®: {self.config['plant']['location']['latitude']}Â°N, {self.config['plant']['location']['longitude']}Â°E
- æµ·æ‹”é«˜åº¦: {self.config['plant']['location']['elevation']} m
- é¢å®šåŠŸç‡: {self.config['plant']['rated_power']} MW
- å‚¨çƒ­æ—¶é•¿: {self.config['plant']['storage_hours']} å°æ—¶

## ä¼˜åŒ–å‚æ•°
- ç®—æ³•: {self.config['optimization']['algorithm']}
- ç§ç¾¤å¤§å°: {self.config['optimization']['population_size']}
- è¿­ä»£æ¬¡æ•°: {self.config['optimization']['max_generations']}
- å®šæ—¥é•œæ•°é‡: {self.config['plant']['num_heliostats']}
- å•é•œé¢ç§¯: {self.config['plant']['heliostat_size']} mÂ²

## ä¼˜åŒ–ç»“æœ
- å¸•ç´¯æ‰˜å‰æ²¿è§£æ•°é‡: {analysis['pareto_front_size']}
- ä¼˜åŒ–è€—æ—¶: {results['metadata']['optimization_time_seconds']:.1f} ç§’

### ç›®æ ‡å‡½æ•°ç»Ÿè®¡

#### å¹´å‘ç”µé‡ (MWh)
- æœ€å°å€¼: {analysis['annual_energy']['min']:.1f}
- æœ€å¤§å€¼: {analysis['annual_energy']['max']:.1f}
- å¹³å‡å€¼: {analysis['annual_energy']['mean']:.1f}
- æ ‡å‡†å·®: {analysis['annual_energy']['std']:.1f}

#### LCOE ($/MWh)
- æœ€å°å€¼: {analysis['lcoe']['min']:.1f}
- æœ€å¤§å€¼: {analysis['lcoe']['max']:.1f}
- å¹³å‡å€¼: {analysis['lcoe']['mean']:.1f}
- æ ‡å‡†å·®: {analysis['lcoe']['std']:.1f}

#### çƒ­é€šé‡å‡åŒ€æ€§
- æœ€å°å€¼: {analysis['flux_uniformity']['min']:.3f}
- æœ€å¤§å€¼: {analysis['flux_uniformity']['max']:.3f}
- å¹³å‡å€¼: {analysis['flux_uniformity']['mean']:.3f}
- æ ‡å‡†å·®: {analysis['flux_uniformity']['std']:.3f}

### æœ€ä½³æŠ˜è¡·è§£
- å¹´å‘ç”µé‡: {analysis['best_compromise_solution']['annual_energy']:.1f} MWh
- LCOE: {analysis['best_compromise_solution']['lcoe']:.1f} $/MWh
- çƒ­é€šé‡å‡åŒ€æ€§: {analysis['best_compromise_solution']['flux_uniformity']:.3f}

## æ•°æ®æ–‡ä»¶è¯´æ˜

1. **pareto_front.csv**: å¸•ç´¯æ‰˜å‰æ²¿ä¸Šæ‰€æœ‰éæ”¯é…è§£çš„ç›®æ ‡å‡½æ•°å€¼
2. **optimization_history.csv**: ä¼˜åŒ–è¿‡ç¨‹çš„æ”¶æ•›å†å²
3. **optimal_layouts/**: æ¯ä¸ªå¸•ç´¯æ‰˜è§£å¯¹åº”çš„å®šæ—¥é•œå¸ƒå±€åæ ‡
4. **dataset_metadata.json**: å®Œæ•´çš„æ•°æ®é›†å…ƒæ•°æ®

## å¼•ç”¨ä¿¡æ¯

å¦‚æœä½¿ç”¨æœ¬æ•°æ®é›†ï¼Œè¯·å¼•ç”¨:
[å¾…å‘è¡¨è®ºæ–‡ä¿¡æ¯]

## è”ç³»ä¿¡æ¯

- ä½œè€…: [æ‚¨çš„å§“å]
- é‚®ç®±: [æ‚¨çš„é‚®ç®±]
- æœºæ„: [æ‚¨çš„æœºæ„]

---
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        with open(f"{self.results_dir}/dataset_summary.md", 'w', encoding='utf-8') as f:
            f.write(report_content)
    
    def visualize_results(self, results: dict):
        """
        å¯è§†åŒ–ä¼˜åŒ–ç»“æœ
        """
        print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # ä½¿ç”¨ä¼˜åŒ–å™¨çš„å¯è§†åŒ–æ–¹æ³•
        self.optimizer.plot_results(results)
        
        print(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {self.results_dir}/figures/")
    
    def run_complete_workflow(self):
        """
        æ‰§è¡Œå®Œæ•´çš„ä¼˜åŒ–å·¥ä½œæµç¨‹
        """
        print("å¯åŠ¨æ•¦ç…Œå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºä¼˜åŒ–å·¥ä½œæµç¨‹")
        print("=" * 80)
        
        try:
            # 1. æ‰§è¡Œä¼˜åŒ–
            results = self.run_optimization()
            
            # 2. åˆ†æç»“æœ
            analysis = self.analyze_results(results)
            
            # 3. ç”Ÿæˆæ•°æ®é›†
            self.generate_dataset(results, analysis)
            
            # 4. å¯è§†åŒ–ç»“æœ
            self.visualize_results(results)
            
            print("\n" + "="*80)
            print("å·¥ä½œæµç¨‹å®Œæˆï¼")
            print(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {os.path.abspath(self.results_dir)}")
            print("="*80)
            
            return results, analysis
            
        except Exception as e:
            print(f"\né”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return None, None


def main():
    """
    ä¸»å‡½æ•°
    """
    print("æ•¦ç…Œ100MWå…‰çƒ­ç”µç«™å®šæ—¥é•œåœºä¼˜åŒ–ç³»ç»Ÿ")
    print("ç”¨äºScientific DataæœŸåˆŠæ•°æ®é›†ç”Ÿæˆ")
    print("\nåŸºäºH-MOWOA-ABCæ··åˆå¤šç›®æ ‡ä¼˜åŒ–ç®—æ³•")
    print("-" * 60)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = DunhuangHeliostatOptimizer()
    
    # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
    results, analysis = optimizer.run_complete_workflow()
    
    if results is not None:
        print("\nğŸ‰ ä¼˜åŒ–æˆåŠŸå®Œæˆï¼")
        print("\nğŸ“Š ä¸»è¦æˆæœ:")
        print(f"   â€¢ ç”Ÿæˆäº† {len(results['pareto_front'])} ä¸ªå¸•ç´¯æ‰˜æœ€ä¼˜è§£")
        print(f"   â€¢ ä¼˜åŒ–äº† {optimizer.config['plant']['num_heliostats']} ä¸ªå®šæ—¥é•œçš„å¸ƒå±€")
        print(f"   â€¢ æ•°æ®é›†ç¬¦åˆFAIRåŸåˆ™ï¼Œå¯ç”¨äºScientific DataæŠ•ç¨¿")
        
        print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   â€¢ å¸•ç´¯æ‰˜å‰æ²¿: {optimizer.results_dir}/pareto_front.csv")
        print(f"   â€¢ ä¼˜åŒ–å¸ƒå±€: {optimizer.results_dir}/optimal_layouts/")
        print(f"   â€¢ å¯è§†åŒ–å›¾è¡¨: {optimizer.results_dir}/figures/")
        print(f"   â€¢ æ•°æ®é›†å…ƒæ•°æ®: {optimizer.results_dir}/dataset_metadata.json")
        
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. æ£€æŸ¥ç”Ÿæˆçš„å¸•ç´¯æ‰˜å‰æ²¿å’Œå¸ƒå±€")
        print("   2. ä¸SolarPILOTè¿›è¡Œè¯¦ç»†ä»¿çœŸéªŒè¯")
        print("   3. å‡†å¤‡Scientific Dataè®ºæ–‡æ‰‹ç¨¿")
        print("   4. å°†æ•°æ®é›†ä¸Šä¼ åˆ°Zenodoè·å–DOI")
    else:
        print("\nâŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯")


if __name__ == "__main__":
    main()